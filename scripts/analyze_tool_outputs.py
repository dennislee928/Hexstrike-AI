#!/usr/bin/env python3
"""
åˆ†ææ‰€æœ‰å®‰å…¨å·¥å…·çš„è¼¸å‡ºç‰¹æ€§
è­˜åˆ¥éœ€è¦æ¨™æº–åŒ–çš„å·¥å…·
"""

import re
from typing import Dict, List, Tuple

# å·¥å…·è¼¸å‡ºç‰¹æ€§åˆ†æ
TOOL_ANALYSIS = {
    "sqlmap": {
        "issues": [
            "äº’å‹•å¼æç¤º (do you want to...)",
            "CSV æ–‡ä»¶è¼¸å‡ºå¼•ç”¨",
            "å†—é•·çš„ ASCII art"
        ],
        "severity": "high",
        "status": "âœ… å·²ä¿®å¾©",
        "fix_applied": True
    },
    
    "hydra": {
        "issues": [
            "äº’å‹•å¼èªè­‰ç¢ºèª",
            "é€²åº¦è¼¸å‡ºæ··äº‚"
        ],
        "severity": "high",
        "status": "ğŸ”´ å¾…ä¿®å¾©",
        "fix_applied": False,
        "suggested_fix": {
            "params": ["-f", "-V", "-o /tmp/hydra.txt"],
            "parser_needed": True
        }
    },
    
    "nmap": {
        "issues": [
            "XML è¼¸å‡ºéœ€è§£æ",
            "å¤šç¨®è¼¸å‡ºæ ¼å¼æ··åˆ"
        ],
        "severity": "medium",
        "status": "ğŸŸ¡ éƒ¨åˆ†æ”¯æŒï¼ˆXML è§£æï¼‰",
        "fix_applied": True,
        "notes": "å·²æœ‰ XML è§£æï¼Œä½†å¯ä»¥æ”¹é€²"
    },
    
    "nikto": {
        "issues": [
            "HTML/CSV/TXT å¤šç¨®æ ¼å¼",
            "è¼¸å‡ºå†—é•·"
        ],
        "severity": "medium",
        "status": "ğŸŸ¡ å¯æ”¹é€²",
        "fix_applied": False,
        "suggested_fix": {
            "params": ["-Format json"],
            "parser_needed": True
        }
    },
    
    "wpscan": {
        "issues": [
            "JSON å’Œæ–‡æœ¬æ··åˆè¼¸å‡º",
            "é€²åº¦ç™¾åˆ†æ¯”"
        ],
        "severity": "medium",
        "status": "ğŸŸ¡ éƒ¨åˆ†æ”¯æŒ",
        "fix_applied": False,
        "suggested_fix": {
            "params": ["--format json", "--no-banner"],
            "parser_needed": True
        }
    },
    
    "nuclei": {
        "issues": [
            "JSONL æµå¼è¼¸å‡ºï¼ˆæ¯è¡Œä¸€å€‹ JSONï¼‰",
            "éœ€è¦åˆä½µçµæœ"
        ],
        "severity": "low",
        "status": "ğŸŸ¢ è¼ƒå¥½ï¼ˆå·²æœ‰ JSONï¼‰",
        "fix_applied": False,
        "suggested_fix": {
            "params": ["-json", "-silent"],
            "parser_needed": True,
            "notes": "éœ€è¦å°‡ JSONL åˆä½µç‚ºå–®å€‹ JSON é™£åˆ—"
        }
    },
    
    "john": {
        "issues": [
            "é€²åº¦è¼¸å‡ºè¦†è“‹",
            "ç„¡çµæ§‹åŒ–è¼¸å‡º",
            "pot æ–‡ä»¶éœ€è®€å–"
        ],
        "severity": "high",
        "status": "ğŸ”´ å¾…ä¿®å¾©",
        "fix_applied": False,
        "suggested_fix": {
            "params": ["--pot=/tmp/john.pot", "--session=/tmp/john_session"],
            "parser_needed": True,
            "notes": "éœ€è¦è®€å– pot æ–‡ä»¶ä¸¦è§£æ"
        }
    },
    
    "hashcat": {
        "issues": [
            "é€²åº¦æ¢ï¼ˆANSI è½‰ç¾©ç¢¼ï¼‰",
            "ç‹€æ…‹æ–‡ä»¶",
            "ç„¡ç›´æ¥çµæ§‹åŒ–è¼¸å‡º"
        ],
        "severity": "high",
        "status": "ğŸ”´ å¾…ä¿®å¾©",
        "fix_applied": False,
        "suggested_fix": {
            "params": ["--quiet", "--potfile-disable", "--outfile=/tmp/hashcat.out"],
            "parser_needed": True,
            "notes": "éœ€è¦è®€å– outfile"
        }
    },
    
    "gobuster": {
        "issues": [
            "é€²åº¦è¼¸å‡º",
            "çµæœåˆ†æ•£åœ¨è¼¸å‡ºä¸­"
        ],
        "severity": "medium",
        "status": "ğŸŸ¡ å¯æ”¹é€²",
        "fix_applied": False,
        "suggested_fix": {
            "params": ["-q", "-o /tmp/gobuster.txt"],
            "parser_needed": True
        }
    },
    
    "ffuf": {
        "issues": [
            "é€²åº¦è¼¸å‡º",
            "å½©è‰²è¼¸å‡ºï¼ˆANSI ç¢¼ï¼‰"
        ],
        "severity": "low",
        "status": "ğŸŸ¢ è¼ƒå¥½ï¼ˆæœ‰ JSON æ¨¡å¼ï¼‰",
        "fix_applied": False,
        "suggested_fix": {
            "params": ["-json", "-o /tmp/ffuf.json", "-s"],
            "parser_needed": False,
            "notes": "ç›´æ¥ä½¿ç”¨ JSON è¼¸å‡ºå³å¯"
        }
    },
    
    "masscan": {
        "issues": [
            "è¼¸å‡ºæ ¼å¼éœ€æŒ‡å®š",
            "çµæœéœ€æ•´ç†"
        ],
        "severity": "low",
        "status": "ğŸŸ¡ å¯æ”¹é€²",
        "fix_applied": False,
        "suggested_fix": {
            "params": ["-oJ /tmp/masscan.json"],
            "parser_needed": False,
            "notes": "ä½¿ç”¨ JSON è¼¸å‡º"
        }
    },
    
    "rustscan": {
        "issues": [
            "å½©è‰²è¼¸å‡º",
            "é€²åº¦å‹•ç•«"
        ],
        "severity": "low",
        "status": "ğŸŸ¢ è¼ƒå¥½",
        "fix_applied": False,
        "suggested_fix": {
            "params": ["--no-color"],
            "parser_needed": True
        }
    },
    
    "subfinder": {
        "issues": [
            "ç°¡å–®æ–‡æœ¬è¼¸å‡ºï¼ˆæ¯è¡Œä¸€å€‹å­åŸŸï¼‰"
        ],
        "severity": "low",
        "status": "ğŸŸ¢ è¼ƒå¥½ï¼ˆç°¡å–®æ ¼å¼ï¼‰",
        "fix_applied": False,
        "suggested_fix": {
            "params": ["-json", "-silent"],
            "parser_needed": False
        }
    },
    
    "amass": {
        "issues": [
            "é€²åº¦è¼¸å‡º",
            "å¤šç¨®è¼¸å‡ºæ ¼å¼"
        ],
        "severity": "medium",
        "status": "ğŸŸ¡ å¯æ”¹é€²",
        "fix_applied": False,
        "suggested_fix": {
            "params": ["-json /tmp/amass.json", "-silent"],
            "parser_needed": False
        }
    },
    
    "metasploit": {
        "issues": [
            "äº’å‹•å¼ console",
            "éœ€è¦ resource è…³æœ¬",
            "è¼¸å‡ºé›£ä»¥è§£æ"
        ],
        "severity": "critical",
        "status": "ğŸ”´ å¾…ä¿®å¾©",
        "fix_applied": False,
        "suggested_fix": {
            "params": ["-q", "-x"],
            "parser_needed": True,
            "notes": "éœ€è¦ä½¿ç”¨ RPC API æˆ–è§£æ resource è…³æœ¬è¼¸å‡º"
        }
    }
}


def generate_priority_list() -> List[Tuple[str, Dict]]:
    """ç”Ÿæˆå„ªå…ˆç´šæ’åºçš„å·¥å…·åˆ—è¡¨"""
    severity_order = {"critical": 0, "high": 1, "medium": 2, "low": 3}
    
    tools = [
        (name, info) 
        for name, info in TOOL_ANALYSIS.items() 
        if not info.get("fix_applied", False)
    ]
    
    tools.sort(key=lambda x: (
        severity_order.get(x[1]["severity"], 99),
        x[0]
    ))
    
    return tools


def generate_report():
    """ç”Ÿæˆåˆ†æå ±å‘Š"""
    print("=" * 80)
    print("ğŸ” å®‰å…¨å·¥å…·è¼¸å‡ºç‰¹æ€§åˆ†æå ±å‘Š")
    print("=" * 80)
    print()
    
    # çµ±è¨ˆ
    total = len(TOOL_ANALYSIS)
    fixed = sum(1 for info in TOOL_ANALYSIS.values() if info.get("fix_applied", False))
    pending = total - fixed
    
    print(f"ğŸ“Š ç¸½è¨ˆ: {total} å€‹å·¥å…·")
    print(f"âœ… å·²ä¿®å¾©: {fixed} å€‹")
    print(f"ğŸ”´ å¾…ä¿®å¾©: {pending} å€‹")
    print(f"ğŸ“ˆ å®Œæˆç‡: {fixed/total*100:.1f}%")
    print()
    
    # æŒ‰åš´é‡ç¨‹åº¦åˆ†çµ„
    print("=" * 80)
    print("ğŸ¯ æŒ‰åš´é‡ç¨‹åº¦åˆ†é¡")
    print("=" * 80)
    print()
    
    for severity in ["critical", "high", "medium", "low"]:
        tools = [
            (name, info) 
            for name, info in TOOL_ANALYSIS.items() 
            if info["severity"] == severity
        ]
        
        if tools:
            emoji = {"critical": "ğŸ”¥", "high": "ğŸ”´", "medium": "ğŸŸ¡", "low": "ğŸŸ¢"}
            print(f"{emoji[severity]} {severity.upper()} ({len(tools)} å€‹)")
            print("-" * 80)
            
            for name, info in tools:
                print(f"  {info['status']} {name}")
                for issue in info["issues"]:
                    print(f"      - {issue}")
                print()
    
    # å„ªå…ˆä¿®å¾©æ¸…å–®
    print("=" * 80)
    print("ğŸš€ å»ºè­°ä¿®å¾©é †åºï¼ˆæœªä¿®å¾©å·¥å…·ï¼‰")
    print("=" * 80)
    print()
    
    priority_list = generate_priority_list()
    
    for idx, (name, info) in enumerate(priority_list, 1):
        print(f"{idx}. {name.upper()} ({info['severity']})")
        print(f"   å•é¡Œ:")
        for issue in info["issues"]:
            print(f"     - {issue}")
        
        if "suggested_fix" in info:
            fix = info["suggested_fix"]
            print(f"   å»ºè­°ä¿®å¾©:")
            print(f"     åƒæ•¸: {' '.join(fix['params'])}")
            print(f"     éœ€è¦è§£æå™¨: {'æ˜¯' if fix.get('parser_needed') else 'å¦'}")
            if "notes" in fix:
                print(f"     å‚™è¨»: {fix['notes']}")
        print()
    
    # å¯¦æ–½å»ºè­°
    print("=" * 80)
    print("ğŸ“ å¯¦æ–½å»ºè­°")
    print("=" * 80)
    print()
    
    print("Phase 1 (æœ¬é€±) - é«˜å„ªå…ˆç´šå·¥å…·:")
    print("  1. âœ… SQLMap (å·²å®Œæˆ)")
    print("  2. ğŸ”´ Hydra")
    print("  3. ğŸ”´ John the Ripper")
    print("  4. ğŸ”´ Hashcat")
    print()
    
    print("Phase 2 (ä¸‹é€±) - ä¸­å„ªå…ˆç´šå·¥å…·:")
    print("  1. ğŸŸ¡ Nikto")
    print("  2. ğŸŸ¡ WPScan")
    print("  3. ğŸŸ¡ Gobuster")
    print("  4. ğŸŸ¡ Amass")
    print()
    
    print("Phase 3 (æœªä¾†) - ä½å„ªå…ˆç´šå·¥å…·:")
    print("  1. ğŸŸ¢ Nuclei (å·²æœ‰ JSONï¼Œéœ€æ•´åˆ)")
    print("  2. ğŸŸ¢ Ffuf (å·²æœ‰ JSON)")
    print("  3. ğŸŸ¢ Subfinder (ç°¡å–®æ ¼å¼)")
    print("  4. ğŸŸ¢ Rustscan (ç§»é™¤å½©è‰²)")
    print()
    
    print("=" * 80)
    print("ğŸ¯ å»ºè­°")
    print("=" * 80)
    print()
    print("1. å‰µå»ºçµ±ä¸€çš„ BaseParser é¡åˆ¥")
    print("2. ç‚ºæ¯å€‹å·¥å…·å¯¦ä½œå°ˆé–€çš„è§£æå™¨")
    print("3. å»ºç«‹è§£æå™¨æ¸¬è©¦å¥—ä»¶")
    print("4. å‰ç«¯çµ±ä¸€ä½¿ç”¨æ¨™æº–åŒ–éŸ¿æ‡‰æ ¼å¼")
    print("5. æ–‡ä»¶åŒ–æ‰€æœ‰å·¥å…·çš„åƒæ•¸å’Œè¼¸å‡ºæ ¼å¼")
    print()


def generate_implementation_template(tool_name: str):
    """ç”Ÿæˆå·¥å…·ä¿®å¾©æ¨¡æ¿"""
    if tool_name not in TOOL_ANALYSIS:
        print(f"âŒ å·¥å…· '{tool_name}' ä¸åœ¨åˆ†ææ¸…å–®ä¸­")
        return
    
    info = TOOL_ANALYSIS[tool_name]
    
    print(f"# {tool_name.upper()} ä¿®å¾©æ¨¡æ¿")
    print()
    print("## 1. è§£æå™¨ (`tools/parsers/{}_parser.py`)".format(tool_name))
    print()
    print("```python")
    print(f'"""')
    print(f"{tool_name.upper()} è¼¸å‡ºè§£æå™¨")
    print(f'"""')
    print()
    print("from typing import Dict, Any")
    print()
    print()
    print(f"class {tool_name.title()}Parser:")
    print(f'    """è§£æ {tool_name.upper()} è¼¸å‡º"""')
    print()
    print("    def parse(self, stdout: str, stderr: str, return_code: int) -> Dict[str, Any]:")
    print("        result = {")
    print('            "findings": [],')
    print('            "summary": {},')
    print('            "warnings": [],')
    print('            "recommendations": []')
    print("        }")
    print("        ")
    print("        # TODO: å¯¦ä½œè§£æé‚è¼¯")
    print("        ")
    print("        return result")
    print()
    print()
    print(f"def parse_{tool_name}_output(stdout: str, stderr: str = '', return_code: int = 0):")
    print(f"    parser = {tool_name.title()}Parser()")
    print("    return parser.parse(stdout, stderr, return_code)")
    print("```")
    print()
    
    print("## 2. ç«¯é»ä¿®æ”¹ (`hexstrike_server.py`)")
    print()
    print("```python")
    print(f'@app.route("/api/tools/{tool_name}", methods=["POST"])')
    print(f"def {tool_name}():")
    print(f'    """Execute {tool_name} with intelligent parsing"""')
    print("    try:")
    print("        params = request.json")
    print("        ")
    print("        # å»ºæ§‹å‘½ä»¤")
    print(f"        command = '{tool_name}'")
    
    if "suggested_fix" in info and "params" in info["suggested_fix"]:
        for param in info["suggested_fix"]["params"]:
            print(f"        command += ' {param}'")
    
    print("        ")
    print("        # åŸ·è¡Œ")
    print("        result = execute_command(command)")
    print("        ")
    print("        # è§£æ")
    print("        if result.get('success'):")
    print("            import sys")
    print("            sys.path.insert(0, '/app/tools/parsers')")
    print(f"            from {tool_name}_parser import parse_{tool_name}_output")
    print("            ")
    print(f"            parsed = parse_{tool_name}_output(")
    print("                result.get('stdout', ''),")
    print("                result.get('stderr', ''),")
    print("                result.get('return_code', 0)")
    print("            )")
    print("            ")
    print("            # è¿”å›æ¨™æº–åŒ–éŸ¿æ‡‰")
    print("            return jsonify({")
    print("                'success': True,")
    print(f"                'tool': '{tool_name}',")
    print("                'summary': parsed['summary'],")
    print("                'findings': parsed['findings'],")
    print("                'metadata': {")
    print("                    'warnings': parsed['warnings'],")
    print("                    'recommendations': parsed['recommendations']")
    print("                },")
    print("                'raw_output': result")
    print("            })")
    print("        ")
    print("        return jsonify(result)")
    print("    except Exception as e:")
    print("        return jsonify({'error': str(e)}), 500")
    print("```")
    print()


if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1:
        # ç”Ÿæˆç‰¹å®šå·¥å…·çš„æ¨¡æ¿
        tool = sys.argv[1].lower()
        generate_implementation_template(tool)
    else:
        # ç”Ÿæˆå®Œæ•´å ±å‘Š
        generate_report()

